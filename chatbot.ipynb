{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Ik wil Anaconda gebruiken:\n",
    "\n",
    "Installeer zo nodig eerst Anaconda. Download Anaconda van https://www.anaconda.com/download\n",
    "\n",
    "In Anaconda navigator klikt u in het menu aan de linkerzijde van het scherm op Environments.\n",
    "Maak een nieuwe virtuele omgeving aan met create.\n",
    "Selecteer uw nieuwe virtuele omgeving door er eenmaal op te klikken. Klik vervolgens op het witte pijltje in het groene rondje.\n",
    "Kies Open terminal. Voor de opdrachtprompt ziet u de padnaam staan waarin u het bestand requirements.txt moet copiëren dat u aantreft in de map Installatie van het workshop dossier.\n",
    "Type in de terminal 'pip3 install -r requirements.txt' en druk op enter.\n",
    "Wacht tot de modules zijn geïnstalleerd.\n",
    "\n",
    "Installeer zonodig de modules van jupiter notebook door in het rechterdeel van het scherm het pakket jupyter te selecteren en installeren.\n",
    "\n",
    "U kunt nu uw notebook gebruiken.\n",
    "\n",
    "\n",
    "\n",
    "of\n",
    "\n",
    "\n",
    "\n",
    "B. Ik wil Visual Studio Code gebruiken:\n",
    "\n",
    "Installeer zonodig eerst python. Download Python versie 3.10.7 van https://www.python.org/downloads/\n",
    "\n",
    "Open een windows terminal door in de windows zoekbalk 'cmd' te typen en op het icoontje te klikken.\n",
    "Ga in de terminal naar de map 'installatie' van het workshop dossier met het commando 'cd c:/padnaardemapinstallatie'. In deze map staat het bestand 'requirements.txt'.\n",
    "Type 'pip3 install -r requirements.txt' en druk op enter.\n",
    "Wacht tot de modules zijn geïnstalleerd.\n",
    "\n",
    "Installeer zo nodig eerst Visual Studio Code. Download Microsoft Visual Studio Code versie 1.85.0 van https://code.visualstudio.com/download\n",
    "\n",
    "Start Visual Studio Code Klik in Visual Studio Code op het incoontje van 'Extensions' in het lint aan de linkerkant van het schermboven.\n",
    "De beschikbare extensions worden nu in een lijst getoond. Type in de zoekbalk boven de lijst 'Jupyter' om de notebook extensie te vinden en te installeren.\n",
    "Klik op de regel van de Jupiter extensie. In het rechterscherm ziet u nu de details van de extensie. Klik op 'Install' om de extensie te installeren.\n",
    "\n",
    "U kunt nu uw notebook in Visual Studio Code gebruiken.\n",
    "\n",
    "\n",
    "\n",
    "De volgende python bibliotheken ('modules') worden gebruikt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run deze code eenmalig om de benodigde software bibliotheken ('modules') te installeren\n",
    "%pip install chromadb==0.4.18\n",
    "%pip install openai==1.3.8\n",
    "%pip install langchain==0.0.348\n",
    "%pip install huggingface-hub==0.16.4\n",
    "%pip install pypdf==3.17.2\n",
    "%pip install openpyxl==3.0.10\n",
    "%pip install docx2txt==0.8\n",
    "%pip install unstructured[all-docs]==0.11.2\n",
    "%pip install sentence-transformers==2.2.2\n",
    "%pip install streamlit==1.29.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importeer de benodigde software bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders.word_document import UnstructuredWordDocumentLoader\n",
    "from langchain.document_loaders.excel import UnstructuredExcelLoader\n",
    "from langchain.document_loaders.powerpoint import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from huggingface_hub import hf_hub_download, login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definieer de parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_WORKING_DIRECTORY = os.getcwd() # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "DOCUMENTEN_FOLDER_NAME = os.path.join(CURRENT_WORKING_DIRECTORY, 'documenten') # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "EMBEDDINGS_FOLDER_NAME = os.path.join(CURRENT_WORKING_DIRECTORY, 'embeddingmodel') # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "VECTORDB_FOLDER_NAME = os.path.join(CURRENT_WORKING_DIRECTORY, 'vectordb') # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "NAME_VECTOR_DB = 'workshop'\n",
    "NAME_COLLECTION = 'workshop_dossier'\n",
    "OPENAI_API_KEY = \"GEEF HIER UW KEY IN\"\n",
    "HUGGINGFACE_API_KEY = \"GEEF HIER UW KEY IN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lees document(en) in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(DOCUMENTEN_FOLDER_NAME):\n",
    "    os.rename(os.path.join(DOCUMENTEN_FOLDER_NAME, file), os.path.join(DOCUMENTEN_FOLDER_NAME, file).replace(' ', '_').lower()) # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "\n",
    "loaders = {\n",
    "        \".pdf\": PyPDFLoader,\n",
    "        \".csv\": CSVLoader,\n",
    "        \".docx\": UnstructuredWordDocumentLoader,\n",
    "        \".xlsx\": UnstructuredExcelLoader,\n",
    "        \".pptx\": UnstructuredPowerPointLoader,\n",
    "        \".txt\": TextLoader\n",
    "    }\n",
    "\n",
    "def maak_de_directory_loader(file_type, directory_path):\n",
    "    return DirectoryLoader(path=directory_path, glob=f\"**/*{file_type}\", loader_cls=loaders[file_type], show_progress=True, use_multithreading=False, max_concurrency=1)\n",
    "\n",
    "pdf_loader = maak_de_directory_loader(\".pdf\", DOCUMENTEN_FOLDER_NAME)\n",
    "csv_loader = maak_de_directory_loader(\".csv\", DOCUMENTEN_FOLDER_NAME)\n",
    "docx_loader = maak_de_directory_loader(\".docx\", DOCUMENTEN_FOLDER_NAME)\n",
    "xlsx_loader = maak_de_directory_loader(\".xlsx\", DOCUMENTEN_FOLDER_NAME)\n",
    "pptx_loader = maak_de_directory_loader(\".pptx\", DOCUMENTEN_FOLDER_NAME)\n",
    "txt_loader = maak_de_directory_loader(\".txt\", DOCUMENTEN_FOLDER_NAME)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file in os.listdir(DOCUMENTEN_FOLDER_NAME):\n",
    "    print(file)\n",
    "    if file.endswith('.pdf'):\n",
    "        documents.extend(pdf_loader.load())\n",
    "    elif file.endswith(\".csv\"):\n",
    "        documents.extend(csv_loader.load())\n",
    "    elif file.endswith(\".docx\"):\n",
    "        documents.extend(docx_loader.load())\n",
    "    elif file.endswith(\".xlsx\"):\n",
    "        documents.extend(xlsx_loader.load())\n",
    "    elif file.endswith(\".pptx\"):\n",
    "        documents.extend(pptx_loader.load())\n",
    "    elif file.endswith(\".txt\"):\n",
    "        documents.extend(txt_loader.load())\n",
    "    elif file.endswith(\".doc\") or file.endswith(\".xls\") or file.endswith(\".ppt\"):\n",
    "        print(\"\")\n",
    "        print(\"Document\", file, \"NIET verwerkt!!!\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "        print(\"Document\", file, \"NIET verwerkt!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Knip document in kleinere tekstfragmenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=750, chunk_overlap=75, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], length_function=len,) # 256 tokens max; bij 3 karakters per token dus ongeveer 750 karakters\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "print(len(chunked_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Definieer het LLM (large language model) voor de embedding van de tekstfragmenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=emb_model, cache_folder=EMBEDDINGS_FOLDER_NAME)\n",
    "login(token = HUGGINGFACE_API_KEY)\n",
    "\n",
    "#text = 'Dit is een voorbeeld'\n",
    "#embedding = embeddings.embed_query(text)\n",
    "#print(len(embedding))\n",
    "#print(embedding[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Tokenize en embedd de tekstfragmenten en sla de word embeddings op in vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_path = VECTORDB_FOLDER_NAME\n",
    "vector_db = Chroma.from_documents(documents=chunked_documents, embedding=embeddings, collection_name=NAME_COLLECTION, persist_directory=vector_db_path)\n",
    "vector_db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Definieer het LLM (large language model) voor de chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY, temperature=0.3, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Maak de vraag-antwoord pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=emb_model, cache_folder=EMBEDDINGS_FOLDER_NAME)\n",
    "vector_db_name = NAME_VECTOR_DB \n",
    "vector_db_folder = VECTORDB_FOLDER_NAME\n",
    "persist_dir = os.path.join(vector_db_folder, vector_db_name)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Stel een vraag aan de chatbot: zoek in de vector db tekstfragmenten voor de context, stop deze context samen met de vraag in een prompt (query) en verkrijg een antwoord via de llm voor de tekst interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Wat is warme grond?\"\n",
    "v = vector_db.similarity_search(q, k=4, include_metadata=True)\n",
    "res = chain({\"input_documents\": v, \"question\": q})\n",
    "print(res[\"output_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
