{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run deze code eenmalig om de benodigde software bibliotheken ('modules') te installeren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb==0.4.18\n",
    "%pip install openai==1.3.8\n",
    "%pip install langchain==0.0.348\n",
    "%pip install huggingface-hub==0.16.4\n",
    "%pip install pypdf==3.17.2\n",
    "%pip install openpyxl==3.0.10\n",
    "%pip install docx2txt==0.8\n",
    "%pip install unstructured[all-docs]==0.11.2\n",
    "%pip install sentence-transformers==2.2.2\n",
    "%pip install streamlit==1.29.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer de benodigde softwarebibliotheken ('modules'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders.word_document import UnstructuredWordDocumentLoader\n",
    "from langchain.document_loaders.excel import UnstructuredExcelLoader\n",
    "from langchain.document_loaders.powerpoint import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from huggingface_hub import hf_hub_download, login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak op uw harde schijf een mappenstructuur aan met de volgende mappen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_WORKING_DIRECTORY = os.getcwd() # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "DOCUMENTEN_FOLDER_NAME = os.path.join(CURRENT_WORKING_DIRECTORY, 'documenten') # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "EMBEDDINGS_FOLDER_NAME = os.path.join(CURRENT_WORKING_DIRECTORY, 'embeddingmodel') # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "VECTORDB_FOLDER_NAME = os.path.join(CURRENT_WORKING_DIRECTORY, 'vectordb') # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "#print(DOCUMENTEN_FOLDER_NAME)\n",
    "#print(EMBEDDINGS_FOLDER_NAME)\n",
    "#print(VECTORDB_FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vul uw codes in voor de website van Huggingface en Openai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"GEEF HIER UW KEY IN\"\n",
    "HUGGINGFACE_API_KEY = \"GEEF HIER UW KEY IN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geef uw dossier en vector store een naam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_COLLECTION = 'workshop_dossier'\n",
    "NAME_VECTOR_DB = 'workshop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definieer het voor het maken van de word embeddings te gebruiken model en download het zonodig van de website van Huggingface:\n",
    "1. voor RAG (Retrieval Augmented Generation) heeft u twee LLM's nodig: één voor het maken van de word embeddings/vectoren en één voor de tekst interface (antwoorden op vragen)\n",
    "2. voor het maken van word embeddings worden tekstfragmenten omgezet in tokens; commerciële llm's als chatgpt van openai berekenen kosten per verwerkte token; bij het maken van word embeddings gaat het al snel om relatief veel tokens en dus ook veel kosten; daarom maken we voor de llm voor het emdedden gebruik van een opensource model van de website van Huggingface\n",
    "3. voor de tekst interface maken we gebruik van het commerciële chatgpt omdat dit een state-of-art model is en omdat het tijdens een chat om te zetten aantal tokens relatief gering is en dus weinig kost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definieer_het_embedding_model():\n",
    "    emb_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=emb_model, cache_folder=EMBEDDINGS_FOLDER_NAME)\n",
    "    login(token = HUGGINGFACE_API_KEY)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vul de vector store:\n",
    "1. verwijder spaties uit documentpaden en documentnamen en zet hoofdletters in documentpaden en documentnamen om in kleine letters\n",
    "2. lees de documenten in de map 'DOCUMENTEN_FOLDER_NAME' in en knip deze op in tekstfragmenten ('chunks') zodat ze door de llm voor de tekst interface kunnen worden gebruikt\n",
    "3. definieer een tekst splitter en knip de ingelezen documenten op in tekstfragmenten ('chunks')\n",
    "4. definieer het voor het maken van de word embeddings te gebruiken model en download het zonodig van de website van Huggingface\n",
    "5. zet de tekstfragmenten (chunks) met behulp van word embeddings om in vectoren en sla deze vectoren op in de vector store 'Chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opslaan_documenten():\n",
    "    for file in os.listdir(DOCUMENTEN_FOLDER_NAME):\n",
    "        os.rename(os.path.join(DOCUMENTEN_FOLDER_NAME, file), os.path.join(DOCUMENTEN_FOLDER_NAME, file).replace(' ', '_').lower()) # NB gebruik GEEN mapnamen met spaties want dat resulteert in een onjuist pad en een foutmelding!!!\n",
    "    loaders = {\n",
    "            \".pdf\": PyPDFLoader,\n",
    "            \".csv\": CSVLoader,\n",
    "            \".docx\": UnstructuredWordDocumentLoader,\n",
    "            \".xlsx\": UnstructuredExcelLoader,\n",
    "            \".pptx\": UnstructuredPowerPointLoader,\n",
    "            \".txt\": TextLoader\n",
    "        }\n",
    "    def maak_de_directory_loader(file_type, directory_path):\n",
    "        return DirectoryLoader(path=directory_path, glob=f\"**/*{file_type}\", loader_cls=loaders[file_type], show_progress=True, use_multithreading=False, max_concurrency=1)\n",
    "    pdf_loader = maak_de_directory_loader(\".pdf\", DOCUMENTEN_FOLDER_NAME)\n",
    "    csv_loader = maak_de_directory_loader(\".csv\", DOCUMENTEN_FOLDER_NAME)\n",
    "    docx_loader = maak_de_directory_loader(\".docx\", DOCUMENTEN_FOLDER_NAME)\n",
    "    xlsx_loader = maak_de_directory_loader(\".xlsx\", DOCUMENTEN_FOLDER_NAME)\n",
    "    pptx_loader = maak_de_directory_loader(\".pptx\", DOCUMENTEN_FOLDER_NAME)\n",
    "    txt_loader = maak_de_directory_loader(\".txt\", DOCUMENTEN_FOLDER_NAME)\n",
    "    documents = []\n",
    "    for file in os.listdir(DOCUMENTEN_FOLDER_NAME):\n",
    "        print(file)\n",
    "        if file.endswith('.pdf'):\n",
    "            documents.extend(pdf_loader.load())\n",
    "        elif file.endswith(\".csv\"):\n",
    "            documents.extend(csv_loader.load())\n",
    "        elif file.endswith(\".docx\"):\n",
    "            documents.extend(docx_loader.load())\n",
    "        elif file.endswith(\".xlsx\"):\n",
    "            documents.extend(xlsx_loader.load())\n",
    "        elif file.endswith(\".pptx\"):\n",
    "            documents.extend(pptx_loader.load())\n",
    "        elif file.endswith(\".txt\"):\n",
    "            documents.extend(txt_loader.load())\n",
    "        elif file.endswith(\".doc\") or file.endswith(\".xls\") or file.endswith(\".ppt\"):\n",
    "            print(\"\")\n",
    "            print(\"Document\", file, \"NIET verwerkt!!!\")\n",
    "        else:\n",
    "            print(\"\")\n",
    "            print(\"Document\", file, \"NIET verwerkt!!!\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=750, chunk_overlap=75, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], length_function=len,) # 256 tokens max; bij 3 karakters per token dus ongeveer 750 karakters\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    print(len(chunked_documents))\n",
    "    embeddings = definieer_het_embedding_model()\n",
    "    vectordb = Chroma.from_documents(documents=chunked_documents, embedding=embeddings, collection_name=NAME_COLLECTION, persist_directory=VECTORDB_FOLDER_NAME)\n",
    "    vectordb.persist()\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak de pipeline voor het beantwoorden van vragen:\n",
    "1. kies een llm van openai, genaamd 'gpt-3.5-turbo', voor de tekstinterface\n",
    "2. stel de query steeds samen ('stuff') uit 1. de vraag van de gebruiker en 2. de context (= uit de vector store opgehaalde meest bijpassende tekstfragmenten); de llm zorgt voor een menselijke communicatie en de context zorgt voor de inbreng van kennis in de query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maken_qa_chain():\n",
    "    model_name = \"gpt-3.5-turbo\"\n",
    "    llm = ChatOpenAI(model_name=model_name, openai_api_key=OPENAI_API_KEY, temperature=0.3, max_tokens=2000)\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doorloop de stappen die nodig zijn om een antwoord te geven op een vraag:\n",
    "1. lees eerst de documenten in de map 'DOCUMENTEN_FOLDER_NAME' in: het resultaat is een gevulde vectore store\n",
    "2. maak de pipeline voor het beantwoorden van vragen: het resultaat is een gedefinieerde pipeline\n",
    "3. zoek in de vectore store de vectoren op met tekstfragmenten die het dichtst in de buurt komen bij de betekenis van de tekst in de vraag; zet daartoe de tekst in de vraag met behulp van word embedding om in een vector en zoek hier in de vectore store de meest vergelijkbare vectoren bij; selecteer de best 'k' vectoren uit de vector store\n",
    "4. zet deze om in tekstfragmenten, voeg deze tekstfragmenten toe aan de tekst van de vraag en biedt alles aan de eerder gemaakte pipeline aan\n",
    "5. vraag het antwoord op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verkrijgen_antwoord(query):\n",
    "    vectordb = opslaan_documenten()\n",
    "    chain = maken_qa_chain()\n",
    "    matching_docs = vectordb.similarity_search(query, k=4)\n",
    "    # geef het aantal teksfragmenten weer\n",
    "    #print(len(matching_docs))\n",
    "    # geef het eerste teksfragment weer\n",
    "    #print(matching_docs[0].page_content)\n",
    "    answer = chain.run(input_documents=matching_docs, question=query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak een eenvoudige webserver en een webpagina voor de chat met behulp van Streamlit; om de webpagina te zien/gebruiken gaat u als volgt te werk:\n",
    "1. open een windows shell door in de windows zoekbalk 'cmd' te typen, enter in te drukken en daarna op het icoontje dat verschijnt te klikken\n",
    "2. type in het venster dat nu opent ' streamlit run \"schijfletter:/het pad en de map waar dit script in staat/workshop_streamlit.py\" '\n",
    "3. in de browser zal nu een webpagina openen met de interface voor de app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_page_config(page_title=\"Documenten zoeker\", page_icon=\":robot:\")\n",
    "st.header(\"Chat met uw pdf documenten\")\n",
    "form_input = st.text_input('Stel uw vraag')\n",
    "submit = st.button(\"Verzend\")\n",
    "if submit:\n",
    "    st.write(verkrijgen_antwoord(form_input))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
